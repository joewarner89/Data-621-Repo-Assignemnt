---
title: "Final_projectData621"
author: Warner Alexis, Saloua Daouki, Souleymane Doumbia, Fomba Kassoh, Lewris Mota
  Sanchez
date: "2024-12-17"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
  pdf_document:
    toc: true
    toc_depth: '3'
  word_document:
    toc: true
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract:

## Introduction:

## 1. Exploratory Data Analysis (EDA):

### 1.1 Load the necessary libraries:

```{r, warning=FALSE }
# Load necessary libraries
library(tidyverse)
library(dplyr)# For data wrangling and visualization
library(ggplot2)     # For plotting
library(DataExplorer) # For automated EDA
library(corrplot)    # For correlation matrix
library(caret)       # For preprocessing and modeling
library(MASS)
library(reshape2)
```

### 1.2 Load the data:

```{r}
# Read the dataset
depr_data <- read.csv("student depression.csv")

# View the first few rows
head(depr_data)
```


### 1.3 Understand the data structure:


```{r}
# Basic structure of the data
str(depr_data)
```

The dataset consists of 27,901 observations and 18 variables. The dataset contains information on students' mental health and related factors, particularly focusing on depression and various stressors. It comprises several demographic, academic, and behavioral variables. These variables include:

- **ID (int):** Unique identifier for each student.

- **Gender (chr):** The gender of the student (Male/Female).

- **Age (int):** The age of the student in years.

- **City (chr):** The city where the student resides.

- **Profession (chr):** Indicates the student's role (e.g., Student).

- **Academic Pressure (int):** Level of academic pressure experienced (numeric).

- **Work Pressure (int):** Level of work pressure experienced (numeric).

- **CGPA (num):** Cumulative Grade Point Average, representing academic performance.

- **Study Satisfaction (int):** Level of satisfaction with study life (numeric).

- **Job Satisfaction (int):** Level of satisfaction with job (numeric).

- **Sleep Duration (chr):** Average sleep duration (e.g., "5-6 hours").8

- **Dietary Habits (chr):** Quality of diet (e.g., Healthy, Moderate).

- **Degree (chr):** Type of degree the student is pursuing (e.g., B.Pharm, BSc).

- **Suicidal Thoughts (chr):** Indicates whether the student has experienced suicidal thoughts (Yes/No).

- **Work/Study Hours (int):** Average hours spent on work or study (numeric).

- **Financial Stress (int):** Level of financial stress experienced (numeric).

- **Family History of Mental Illness (chr):** Indicates if there is a family history of mental illness (Yes/No).

- **Depression (int):** The target variable indicating whether the student has depression (Yes/No).

```{r}
# Summary statistics of the data
summary(depr_data)
```

The dataset consists of different variables that are related to demographic, academic, and mental health characteristics. The target variable, Depression, is binary, with 58.6% of responses indicating depression (1). Key predictors include Academic Pressure, ranging from 0 to 5 with a mean of 3.14, and Financial Stress, also ranging from 1 to 5 with a mean of 3.14 (three missing values). Study Satisfaction scores range from 0 to 5, with a mean of 2.94, while Work Pressure is mostly absent (mean: 0.0004). CGPA varies between 0 and 10, with a mean of 7.66. Additionally, Sleep Duration and Dietary Habits provide qualitative insights into students' lifestyles, while variables like Age (mean: 25.82) and Family History of Mental Illness ("Yes" or "No") offer further potential predictors for mental health outcomes. These predictors can help in analyzing factors associated with depression in students.

### 1.4 Check for missing values:

```{r}
# Check for missing values
colSums(is.na(depr_data))
```

Based on the output above, the dataset has minimal missing values. Only the Financial Stress variable contains missing values (3 cases); all other variables have complete data. However, visualizing the missing data can make it easier to identify patterns. Here is a plot showing the missing values:


```{r}
# Visualize missing data
plot_missing(depr_data)
```

Since Financial Stress is an ordinal variable (ranging from 1 to 5), we used median imputation the median is a robust measure that minimizes the impact of outliers.

```{r}
# Impute missing values in Financial Stress with the median
depr_data$Financial.Stress[is.na(depr_data$Financial.Stress)] <- median(depr_data$Financial.Stress, na.rm = TRUE)
```


```{r}
# Verify no missing values remain
sum(is.na(depr_data$Financial.Stress))
```



The bar charts in the visualizations summarize key insights about the mental health factors affecting students based on the dataset of 27,901 observations.

1. **Academic Pressure**: The distribution of academic pressure shows that the majority of students experience moderate to high academic stress (levels 3 and 5), with fewer reporting lower levels of pressure.

2. **Work Pressure**: Most students report minimal work pressure (0 level), suggesting that academic stress might be a larger contributor to their mental health challenges.

3. **Sleep Duration**: The chart indicates variability in students' sleep patterns, with a significant number sleeping **less than 5 hours** and **5-6 hours**, which may indicate poor sleep habits associated with stress.

4. **Financial Stress**: Financial stress levels are evenly distributed across categories, but a noticeable portion of students report experiencing high financial stress (level 5), which could exacerbate their mental health issues.

5. **Depression Status**: A significant portion of students (approximately 11,000) report having depression, but the majority (over 16,000) do not experience depression. This suggests that while depression is prevalent, there are identifiable stressors (e.g., academic and financial) that can be addressed to mitigate mental health risks.

Overall, the data highlights the impact of academic stress, sleep deprivation, and financial burdens on students' mental health, particularly depression.


```{r}
data <- depr_data
# Visualization for Academic Pressure
ggplot(data, aes(x = Academic.Pressure)) +
  geom_bar(fill = "skyblue") +
  labs(title = "Distribution of Academic Pressure", x = "Pressure Level", y = "Frequency") +
  theme_minimal()

# Visualization for Work Pressure
ggplot(data, aes(x = Work.Pressure)) +
  geom_bar(fill = "lightgreen") +
  labs(title = "Distribution of Work Pressure", x = "Pressure Level", y = "Frequency") +
  theme_minimal()

# Visualization for Sleep Duration
ggplot(data, aes(x = Sleep.Duration)) +
  geom_bar(fill = "coral") +
  labs(title = "Distribution of Sleep Duration", x = "Sleep Duration Category", y = "Frequency") +
  theme_minimal()

# Visualization for Financial Stress
ggplot(data, aes(x = Financial.Stress)) +
  geom_bar(fill = "gold") +
  labs(title = "Distribution of Financial Stress", x = "Stress Level", y = "Frequency") +
  theme_minimal()

# Visualization for Depression
ggplot(data, aes(x = Depression)) +
  geom_bar(fill = "purple") +
  scale_x_discrete(labels = c("No Depression", "Depression")) +
  labs(title = "Depression Status", x = "Depression", y = "Frequency") +
  theme_minimal()



```






Excellent! The 3 missing values have been addressed. Let's move on to further data cleaning and transformation.

```{r}
# Convert relevant columns to factors
# summarization 

# Identify categorical columns
categorical_cols <- sapply(data, is.character) | sapply(data, is.factor)

# Apply label encoding to all categorical columns
data[categorical_cols] <- lapply(data[categorical_cols], function(x) as.numeric(as.factor(x)))

```





The graphs provide a detailed analysis of the relationship between various features and the target variable, **"Depression"**. The **P-Values of Features** chart highlights the statistical significance of each feature, with smaller p-values indicating stronger associations. Features such as **"Academic Pressure"**, **"Financial Stress"**, and **"Have you ever had suicidal thoughts?"** are highly significant, as evidenced by their very low p-values, while features like **"ID"**, **"Gender"**, and **"Work Pressure"** show high p-values, indicating minimal significance in predicting depression.

The **Correlations of Features with Depression** chart further reveals the strength and direction of relationships between the features and depression. **"Have you ever had suicidal thoughts?"**, **"Academic Pressure"**, and **"Financial Stress"** exhibit strong positive correlations with depression, suggesting that higher values in these features are associated with an increased likelihood of depression. Conversely, features such as **"Age"** and **"Study Satisfaction"** show negative correlations, indicating that older students and those satisfied with their studies are less likely to experience depression.

The **Correlation Heatmap** visualizes pairwise correlations among all variables, emphasizing the relationships identified earlier. Strong positive correlations are observed between **"Depression"** and features like **"Academic Pressure"**, **"Financial Stress"**, and **"Suicidal Thoughts"**, while weaker or negative correlations are seen for variables like **"Age"**, **"CGPA"**, and **"Study Satisfaction"**. Additionally, the heatmap highlights some multicollinearity among independent variables, which may require further exploration. Overall, the analysis pinpoints the most impactful predictors of depression among students, particularly academic and financial stressors, while highlighting less relevant features such as **"ID"** and **"Gender"**.




```{r}
# Correlation matrix
numeric_vars <- data %>% dplyr::select(where(is.numeric))

cor_matrix <- cor(numeric_vars, use = "complete.obs")
corrplot(cor_matrix, method = "number")
table(cor_matrix)




#####
# Define the target variable
target <- "Depression"

# Initialize an empty data frame to store results
results <- data.frame(Feature = character(), Correlation = numeric(), P_value = numeric(), stringsAsFactors = FALSE)

# Perform univariate analysis
for (col in names(data)) {
  if (col != target) {
    # Calculate correlation and p-value
    correlation <- cor(data[[col]], data[[target]], use = "complete.obs", method = "pearson")
    p_value <- cor.test(data[[col]], data[[target]], method = "pearson")$p.value
    
    # Append results to the data frame
    results <- rbind(results, data.frame(Feature = col, Correlation = correlation, P_value = p_value))
  }
}

# Sort the results by p-value
results <- results %>% arrange(P_value)

# Print the results
print(results)


# Create a bar chart for p-values
ggplot(results, aes(x = reorder(Feature, P_value), y = P_value)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "P-Values of Features", x = "Features", y = "P-Value") +
  theme_minimal()

# Create a bar chart for correlations
ggplot(results, aes(x = reorder(Feature, Correlation), y = Correlation)) +
  geom_bar(stat = "identity", fill = "lightgreen") +
  coord_flip() +
  labs(title = "Correlations of Features with Depression", x = "Features", y = "Correlation") +
  theme_minimal()

```



The first graph, which uses boxplots, displays the distribution of all features segmented by the target variable **Depression** (1 and 2), allowing us to observe the spread, variability, and central tendencies. Features like **Academic Pressure** and **Financial Stress** have higher medians for students with depression, while **Sleep Duration** and **Study Satisfaction** show lower medians, indicating inadequate sleep and dissatisfaction with studies as potential contributors to depression. Minimal variation in features such as **ID** and **Work Pressure** suggests they have limited influence on depression outcomes. The second graph, using density plots, provides a smoother visualization of the feature distributions across depression categories, showing distinct peaks for key features like **Academic Pressure**, **Financial Stress**, and **Sleep Duration**, where higher stress and shorter sleep durations align with depression. Features like **"Have you ever had suicidal thoughts?"** exhibit clear separation, strongly correlating with depression. In contrast, **Work Pressure** and **Job Satisfaction** show flat distributions, suggesting limited variability. Both graphs emphasize the critical role of stress-related and behavioral factors, particularly **Academic Pressure**, **Financial Stress**, and **Sleep Duration**, while highlighting **Suicidal Thoughts** as a significant predictor of depression. Features like **ID** and **Work Pressure** remain less informative, reinforcing the importance of stressors and lifestyle factors in understanding depression among students.



```{r}

# Melt the dataset for faceting
data_melted <- melt(data, id.vars = "Depression")

# Create faceted density plot
ggplot(data_melted, aes(x = value, fill = as.factor(Depression))) +
  geom_density(alpha = 0.4, color = "blue") +
  facet_wrap(~variable, scales = "free") +
  ggtitle("Distribution of All Features by TARGET") +
  xlab("Value") +
  ylab("Density") +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    strip.text = element_text(size = 8),
    axis.text.x = element_text(size = 6)
  )


# Checking Outliers 
```





We removed ouliers  in Age , Profession, Work.Presssure, Job.Statisfaction and The longest variables.


```{r}
remove_outliers <- function(data, cols = NULL) {
  # If no columns are specified, apply to all numeric columns
  if (is.null(cols)) {
    cols <- names(data)[sapply(data, is.numeric)]
  }
  
  # Loop through each specified column
  for (col in cols) {
    Q1 <- quantile(data[[col]], 0.25, na.rm = TRUE)  # First quartile
    Q3 <- quantile(data[[col]], 0.75, na.rm = TRUE)  # Third quartile
    IQR <- Q3 - Q1                                  # Interquartile range
    lower_bound <- Q1 - 1.5 * IQR                   # Lower threshold
    upper_bound <- Q3 + 1.5 * IQR                   # Upper threshold
    
    # Filter the data to remove outliers
    data <- data[data[[col]] >= lower_bound & data[[col]] <= upper_bound | is.na(data[[col]]), ]
  }
  
  return(data)
}


cleaned_data <- remove_outliers(data)
#cols= c('Age','Profession','Work.Pressure','CGPA','Job.Satisfaction','Sleep.Duration','Have.you#.ever.had.suicidal.thoughts..'))
```






```{r}
# Standardize column names (replace spaces and special characters with underscores)
colnames(depr_data) <- gsub("\\.|\\s+", "_", colnames(depr_data))

# Verify the updated structure
str(depr_data)
```


```{r}
#Change column names for simplification
 data <- data %>% rename(Suicidal_Thoughts = Have.you.ever.had.suicidal.thoughts..,
                 Mental_Illness_History = Family.History.of.Mental.Illness
                 )

# Divinde the data into train and test

# Split data into training and testing sets
trainIndex <- createDataPartition(data$Depression, p = 0.7, list = FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

```


##  MODEL DEVELOPMENT



The analysis of deviance compares the null model, which includes no predictors, to the full model containing all predictors. The **null model deviance** is **26,503.14**, representing the total unexplained variation in the response variable (`Depression`). When predictors are included, the **full model deviance** reduces to **14,578.81**, indicating a significant improvement in model fit. The **deviance difference** is **11,924.33**, with a **degrees of freedom difference of 17**, corresponding to the number of predictors added. This large reduction in deviance highlights the contribution of the predictors in explaining variability. The p-value for the chi-squared test is effectively **0**, confirming that the improvement in model fit is highly significant. Therefore, predictors such as **Academic Pressure**, **Financial Stress**, **Study Satisfaction**, and **Suicidal Thoughts** play a critical role in explaining the probability of depression, as they significantly reduce the unexplained variation in the response variable.




```{r}
# Ensure the target variable is a factor
data$Depression <- as.factor(data$Depression)

# Split data into training and testing sets
trainIndex <- createDataPartition(data$Depression, p = 0.7, list = FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Perform logistic regression
model <- glm(Depression ~ Age + Gender + Academic.Pressure + Work.Pressure + 
             Study.Satisfaction + Sleep.Duration + Financial.Stress, 
             data = trainData, family = binomial)

# Summary of the model
summary(model)

# Perform ANOVA for Deviance Analysis
deviance_analysis <- anova(model, test = "Chisq")
print("Deviance Analysis Table:")
print(deviance_analysis)

# Deeper Deviance Analysis using Null and Full Model
null_model <- glm(Depression ~ 1, data = trainData, family = binomial)
full_model <- glm(Depression ~ ., data = trainData, family = binomial)

deviance_null <- null_model$deviance
deviance_full <- full_model$deviance

# Deviance Difference and Chi-Square Test
deviance_diff <- deviance_null - deviance_full
df_diff <- null_model$df.residual - full_model$df.residual
p_value <- pchisq(deviance_diff, df = df_diff, lower.tail = FALSE)

cat("\nNull Model Deviance:", deviance_null)
cat("\nFull Model Deviance:", deviance_full)
cat("\nDeviance Difference:", deviance_diff)
cat("\nDegrees of Freedom Difference:", df_diff)
cat("\nP-Value for Deviance Difference Test:", p_value, "\n")

# Predict probabilities on the test set
testData$predicted_prob <- predict(model, newdata = testData, type = "response")

# Thresholding to classify predictions
testData$predicted_class <- ifelse(testData$predicted_prob > 0.5, 1, 0)

# Confusion Matrix
confusionMatrix(as.factor(testData$predicted_class), testData$Depression)

# Plotting ROC Curve
library(pROC)
roc_curve <- roc(testData$Depression, testData$predicted_prob)
plot(roc_curve, main = "ROC Curve for Depression Prediction")
auc(roc_curve)

```

The model achieves an accuracy of 77.92% with a balanced approach to detecting both 0 (no depression) and 1 (depression). The sensitivity (70.65%) indicates that the model captures most cases of depression, while the specificity (83.06%) shows good performance in identifying individuals without depression. Key metrics like PPV (74.70%) and NPV (79.99%) demonstrate its reliability in predictions. While errors in classification are not evenly distributed (McNemar's Test: p-value = 1.361e-05), the overall balanced accuracy (76.86%) indicates that the model performs well for both classes.



**Model 2** 


The results of the logistic regression model can be interpreted using the provided odds ratios. The **intercept** has an odds value of **0.7518**, representing the baseline odds when all predictors are set to zero, which indicates a lower likelihood of the event (e.g., depression). For **Age**, the odds ratio is **0.9427**, meaning that for each one-unit increase in age, the odds of the event decrease by a factor of **0.9427**, or approximately **6.1%**. Similarly, **Study Satisfaction** has an odds ratio of **0.8759**, suggesting that a one-unit increase reduces the odds of the event by **12.4%**.

On the other hand, **Academic Pressure** and **Financial Stress** have odds ratios of **1.6332** and **1.3937**, respectively. This indicates a **positive relationship** with the outcome: a one-unit increase in academic pressure increases the odds of the event by approximately **63.3%**, while a one-unit increase in financial stress increases the odds by about **39.4%**. Finally, **Sleep Duration** has a slightly negative effect, with an odds ratio of **0.9648**, meaning the odds decrease by **3.5%** for each additional unit of sleep. Overall, **Academic Pressure** and **Financial Stress** emerge as strong predictors that increase the likelihood of the event, while **Age**, **Study Satisfaction**, and **Sleep Duration** have negative relationships, reducing the odds of the event.

```{r}
model2 <- glm(Depression ~ Age  + Academic.Pressure  + 
             Study.Satisfaction + Sleep.Duration + Financial.Stress, 
             data = trainData, family = binomial(link = 'probit'))
summary(model2)



#Odds Event
or_m2 <- exp(coef(model2))
print(or_m2)


# Predict probabilities on the test set using Probit Model
testData$predicted_prob_probit <- predict(model2, newdata = testData, type = "response")

# Odds Analysis: Convert probabilities to odds
testData$predicted_odds_probit <- testData$predicted_prob_probit / (1 - testData$predicted_prob_probit)

# Display a sample of predicted probabilities and odds
print("Sample of Predicted Probabilities and Odds (Probit Model):")
head(testData[, c("Depression", "predicted_prob_probit", "predicted_odds_probit")])

# Confusion Matrix for Probit Model
testData$predicted_class_probit <- ifelse(testData$predicted_prob_probit > 0.5, 1, 0)
confusionMatrix(as.factor(testData$predicted_class_probit), testData$Depression)

# Plotting ROC Curve for Probit Model
roc_curve_probit <- roc(testData$Depression, testData$predicted_prob_probit)
plot(roc_curve_probit, main = "ROC Curve for Probit Model")
auc(roc_curve_probit)

# Predict probabilities on the test set
testData$predicted_prob <- predict(model, newdata = testData, type = "response")

# Thresholding to classify predictions
testData$predicted_class <- ifelse(testData$predicted_prob > 0.5, 1, 0)

# Confusion Matrix
confusionMatrix(as.factor(testData$predicted_class), testData$Depression)

# Plotting ROC Curve
library(pROC)
roc_curve <- roc(testData$Depression, testData$predicted_prob)
plot(roc_curve, main = "ROC Curve for Depression Prediction")
auc(roc_curve)

# Calculate Pseudo R-squared
pseudo_r2 <- 1 - (model$deviance / null_model$deviance)
cat("\nPseudo R-squared:", pseudo_r2, "\n")

# Odds Probability Analysis
# Display sample of predicted probabilities and odds from the logistic model
testData$predicted_odds <- testData$predicted_prob / (1 - testData$predicted_prob)
print("Sample of Predicted Probabilities and Odds (Logistic Model):")
head(testData[, c("Depression", "predicted_prob", "predicted_odds")])

```



The ROC curve for the Probit Model, along with key performance metrics, confirms the model's strong ability to classify the binary outcome (`Depression`). The **Area Under the Curve (AUC)** is **0.85**, indicating excellent discrimination between the two classes. The model achieves an overall **accuracy of 77.92%**, which is significantly higher than the **No Information Rate (58.55%)**, with a p-value of **< 2.2e-16**, proving that its performance is far better than random guessing. The model balances both sensitivity and specificity, with a **sensitivity of 70.65%** (correctly identifying 70.65% of positives) and a **specificity of 83.06%** (avoiding 83.06% of false positives). The **balanced accuracy** is **76.86%**, showing fair performance across both classes, and the **Kappa statistic** of **0.5414** indicates moderate agreement between predictions and true outcomes. Additionally, the **Pseudo R-squared** value of **0.3042** suggests that the model explains approximately **30.4%** of the variability in the response variable. Overall, the ROC curve demonstrates the model's strong performance, effectively balancing true positive and false positive rates across various thresholds, with robust metrics to support its reliability in predicting depression.


