---
title: "HW#3:LOGISTIC_REGRESSION"
author: "Saloua Daouki"
date: "2024-10-31"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
  pdf_document:
    toc: true
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Our objective is to build a binary logistic regression model on the training data set to predict whether the neighborhood will be at risk for high crime levels. We will provide classifications and probabilities for the evaluation data set using our binary logistic regression model. We can only use the variables given to us (or, variables that we derive from the variables provided). Below is a short description of the variables of interest in the data set:

• zn: proportion of residential land zoned for large lots (over 25000 square feet) (predictor variable)

• indus: proportion of non-retail business acres per suburb (predictor variable)

• chas: a dummy var. for whether the suburb borders the Charles River (1) or not (0) (predictor variable)

• nox: nitrogen oxides concentration (parts per 10 million) (predictor variable)

• rm: average number of rooms per dwelling (predictor variable)

• age: proportion of owner-occupied units built prior to 1940 (predictor variable)

• dis: weighted mean of distances to five Boston employment centers (predictor variable)

• rad: index of accessibility to radial highways (predictor variable)

• tax: full-value property-tax rate per $10,000 (predictor variable)

• ptratio: pupil-teacher ratio by town (predictor variable)

• lstat: lower status of the population (percent) (predictor variable)

• medv: median value of owner-occupied homes in $1000s (predictor variable)

• target: whether the crime rate is above the median crime rate (1) or not (0) (response variable)

## 1. DATA EXPLORATION

### a. Load the Data and Check Size/Variables

```{r}
# Load necessary libraries
library(tidyverse)

# Load the datasets
train_data <- read.csv("crime-training-data_modified.csv")  # Training data
eval_data <- read.csv("crime-evaluation-data_modified.csv")  # Evaluation data

# Check the dimensions and structure of the datasets
dim(train_data)
str(train_data)
```

### b. Calculate Mean, Standard Deviation, and Median

```{r}
# Summary statistics for training data
summary_stats <- train_data %>% summarise(across(everything(), list(mean = ~mean(.x, na.rm = TRUE), 
                                                                      sd = ~sd(.x, na.rm = TRUE), 
                                                                      median = ~median(.x, na.rm = TRUE))))
print(summary_stats)
```

### c. Bar Chart and Box Plot

```{r}
# Box plot for continuous variables vs. target
ggplot(train_data, aes(x = factor(target), y = rm)) + 
  geom_boxplot() + 
  labs(title = "Box Plot of Rooms vs. Crime Rate", x = "High Crime Rate (1 = Yes, 0 = No)", y = "Average Rooms")

# Bar chart for categorical variable (e.g., chas)
ggplot(train_data, aes(x = factor(chas), fill = factor(target))) +
  geom_bar(position = "dodge") +
  labs(title = "Bar Chart of Charles River Bordering vs. Crime Rate", x = "Borders Charles River (1 = Yes, 0 = No)", fill = "High Crime Rate")
```

### d. Correlation Matrix

```{r}
# Correlation matrix for training data
correlation_matrix <- cor(train_data %>% select(-target), use = "complete.obs")
print(correlation_matrix)

# Visualization of correlation matrix
library(ggcorrplot)
ggcorrplot(correlation_matrix, lab = TRUE)
```
### e. Calculating skewness and checking nonlinearity

```{r}
library(ggplot2)
ggplot(train_data, aes(x = medv)) + geom_histogram(bins = 30) + ggtitle("Distribution of medv")

# Calculate skewness
library(moments)
skewness_value <- skewness(train_data$medv)
print(skewness_value)
```
The medv variable is positively skewed; we can see it from the histogram above where the right hand side tail is longer and also from the skewness value of 1.080167, this tells us that log transformation is suitable for the variable 'medv'.

```{r}
#checking nonlinearity between rm and target
ggplot(train_data, aes(x = rm, y = target)) + geom_point() + geom_smooth(method = "loess")
```

Baed on the scatter plot above, the relationship between the rm and target is non-linear, we can use polynomial terms, perhaps square of rm.

### f. Check for Missing Values

```{r}
# Check for missing values in training data
missing_values <- sapply(train_data, function(x) sum(is.na(x)))
print(missing_values)
```

## 2. DATA PREPARATION 

Since there is no missing values in the provided data, we can skip handling them in this section.

### a.  Mathematical Transformations

```{r}
# Log transformation of medv
train_data <- train_data %>%
  mutate(log_medv = log(medv + 1))  # Adding 1 to avoid log(0)

# Adding a quadratic term for rm
train_data <- train_data %>%
  mutate(rm_squared = rm^2)
```

## 3. BUILD MODELS 

### a. Build Logistic Regression Models

#### a.1. Model 1: Using All Predictors

```{r}
model1 <- glm(target ~ zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + lstat, 
              data = train_data, 
              family = "binomial")
summary(model1)
```

Here are the key coefficient of model 1

- nox (Nitrogen oxides concentration): 44.02299 indicates that for each unit increase in nox, the log-odds of high crime increase significantly, which is very strong evidence (p < 0.001); highly significant.

- rm (Average number of rooms): 1.001582 indicates that an increase of one room is associated with a significant increase in the likelihood of high crime (p < 0.05), statistically significant.

- dis (Weighted mean distance to employment centers): 0.4922 indicates that as distance increases, the likelihood of high crime increases (p < 0.05), statistically significant.

- rad (Accessibility to radial highways): 0.6359 shows that increased access is positively associated with high crime levels (p < 0.001); highly significant.

- tax (Property-tax rate): -0.007331 suggests that higher property tax rates are associated with lower likelihood of high crime (p < 0.05), statistically significant.

- ptratio (Pupil-teacher ratio): 0.2202 indicates a positive association with high crime rates (p < 0.05)statistically significant.

- lstat (Lower status of the population): The coefficient is not statistically significant (p = 0.3679), suggesting it may not be a useful predictor in this model because it is not significant.

#### a.2. Model 2: With Transformations and Selected Predictors

```{r}
model2 <- glm(target ~ log_medv + rm + rm_squared + lstat, data = train_data, family = "binomial")
summary(model2)
```

Here are the interpretations of each of the predictors used in model 2:

- log_medv: -1.20293 indicates that for every one-unit increase in the log of the median value of owner-occupied homes, the log-odds of high crime decreases. The p-value is 0.066306, which is marginally significant (p < 0.1), suggesting this predictor might still have some importance but is not conventionally significant at the 0.05 level.

- rm: -9.29450 indicates that for each additional room in a dwelling, the log-odds of high crime decreases significantly (p < 0.001). This suggests a strong negative relationship between the average number of rooms and high crime levels.

- rm_squared: 0.78630 indicates a positive association with the log-odds of high crime, suggesting that as the number of rooms increases, the effect of rooms on high crime becomes more positive at higher levels of rm (p < 0.001).

- lstat: 0.19639 indicates that for each one-unit increase in the lower status of the population, the log-odds of high crime increase significantly (p < 0.001).

#### a.3. Model 3: Stepwise Regression for Variable Selection

```{r}
model3 <- stepAIC(glm(target ~ ., data = train_data, family = "binomial"), direction = "both")
summary(model3)
```
Model 3 reveals that the following predictors are statistically significant with p < 0.05;

- zn (*)
- nox (***)
- rm (***)
- age (**)
- dis (**)
- rad (***)
- tax (***)
- ptratio (**)
- rm_squared (***)

Now that we have three models, we can use their AIC values to compare them and conclude which model is better fit: the AIC value of 205.14 for model 3 shows a better fit than both Model 1 (AIC = 223.95) and Model 2 (AIC = 493.96). This suggests that Model 3 is a more efficient model in terms of balancing goodness of fit and complexity.

## 4. SELECT MODELS 

### a. Predictions on Evaluation Data

Now that we decided which model is the best, we can predict on evaluation data :

```{r}
# Calculate log_medv and rm_squared in evaluation data
eval_data$log_medv <- log(eval_data$medv)                # Create log_medv
eval_data$rm_squared <- eval_data$rm^2                    # Create rm_squared

# Predictions on evaluation data using the best model (model3 in this case)
eval_data$pred_prob <- predict(model3, newdata = eval_data, type = "response")
eval_data$pred_class <- ifelse(eval_data$pred_prob > 0.5, 1, 0)
```


### b. Confusion Matrix and Metrics

```{r}
length(eval_data$target)
length(eval_data$pred_class)
```

```{r}
# Inspect eval_data
str(eval_data)
summary(eval_data)

# Check if target variable is present
if ("target" %in% colnames(eval_data)) {
    cat("Target variable exists in eval_data.\n")
} else {
    cat("Target variable is missing from eval_data.\n")
}
```

```{r}
# Summary of predicted probabilities
summary(eval_data$pred_prob)

# Summary of predicted classes
table(eval_data$pred_class)
```



```{r}
# Make predictions on training data
train_data$pred_prob <- predict(model3, newdata = train_data, type = "response")
train_data$pred_class <- ifelse(train_data$pred_prob > 0.5, 1, 0)

# Confusion Matrix
confusion_matrix <- table(train_data$target, train_data$pred_class)
cat("Confusion Matrix:\n")
print(confusion_matrix)  # Ensure the confusion matrix displays

# Accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")

# Classification Error Rate
classification_error_rate <- 1 - accuracy
cat("Classification Error Rate:", classification_error_rate, "\n")

# Sensitivity and Specificity
sensitivity <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
specificity <- confusion_matrix[1, 1] / sum(confusion_matrix[1, ])
cat("Sensitivity:", sensitivity, "\n")
cat("Specificity:", specificity, "\n")

# Precision
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
cat("Precision:", precision, "\n")

# F1 Score
f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
cat("F1 Score:", f1_score, "\n")

# ROC Curve and AUC
library(pROC)
roc_obj <- roc(train_data$target, train_data$pred_prob)
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")

# Plot ROC Curve
plot(roc_obj, main = "ROC Curve", xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate")
abline(a = 0, b = 1, lty = 2, col = "red") # Add a diagonal line for reference
```

- Confusion Matrix:

True Negatives (0 predicted as 0): 218

False Positives (0 predicted as 1): 19

False Negatives (1 predicted as 0): 20

True Positives (1 predicted as 1): 209

- Accuracy (91.63%): Indicates that the model correctly predicts the class for about 92% of the training samples, a strong result.

- Classification Error Rate (8.37%): Complements the accuracy, showing the proportion of misclassifications, which is low.

- Sensitivity (91.27%): Represents the model’s ability to correctly identify positive cases (target = 1). This high sensitivity means the model is effective in identifying positives.

- Specificity (91.98%): Indicates the model’s ability to correctly identify negative cases (target = 0). A similarly high value here shows balanced performance across classes.

- Precision (91.67%): Shows how many of the instances predicted as positive are actually positive, which is crucial if the cost of false positives is high.
F1 Score (91.47%): Balances precision and sensitivity, confirming the model’s consistent performance.

- AUC (0.9766): Reflects excellent overall separability between classes, meaning the model is likely distinguishing well between positive and negative cases.

These metrics suggest a well-performing model, especially given the high AUC and balanced sensitivity and specificity.

