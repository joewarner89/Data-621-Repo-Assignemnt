ggplot(t, mapping = aes(x=track_artist, y=speechiness, fill=speechiness))+
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "grey20", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
spotify_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness) %>%
ggplot(t, mapping = aes(x=track_artist, y=speechiness, fill=speechiness))+
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "grey20", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
spotify_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness)
spotify_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness, album_release_year)
# spotify
album_data <- spotify_data %>% arrange(desc(duration_ms)) %>%
select(track_album_name,track_name,track_artist,speechiness,loudness,tempo, danceability,speechiness ,duration_ms,album_release_year) %>%
filter( album_release_year >= 2001)
head(album_data)
album_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness) %>%
ggplot(t, mapping = aes(x=track_artist, y=speechiness, fill=speechiness))+
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "grey20", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
album_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness, album_release_year)
# spotify
album_data <- spotify_data %>% arrange(desc(duration_ms)) %>%
select(track_album_name,track_name,track_artist,speechiness,loudness,tempo, danceability,speechiness ,duration_ms,album_release_year) %>%
filter( album_release_year >= 2001 & album_release_year <= 2023)
album_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness) %>%
ggplot(t, mapping = aes(x=track_artist, y=speechiness, fill=speechiness))+
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "grey20", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
album_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness, album_release_year)
spotify_data %>% head(10)  %>% arrange(desc(speechiness)) %>% select(track_artist, speechiness, album_release_year)
# artists with most releases
album_data %>% group_by(Artist = track_artist) %>%
summarise(No_of_tracks = n()) %>%
arrange(desc(No_of_tracks)) %>%
top_n(15, wt = No_of_tracks) %>%
ggplot(aes(x = Artist, y = No_of_tracks, fill = No_of_tracks)) +
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "blue2", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+labs(height=10, width=5)+
coord_flip() + labs(title = "artists with the most releases", x = "artists", y = "no of releases")
# artists with most releases
album_data %>% group_by(Artist = track_artist) %>%
summarise(No_of_tracks = n()) %>%
arrange(desc(No_of_tracks)) %>%
top_n(15, wt = No_of_tracks) %>%
ggplot(aes(x = Artist, y = No_of_tracks, fill = No_of_tracks)) +
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "blue2", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+labs(height=10, width=5)+
coord_flip() + labs(title = "artists with the most releases", x = "artists", y = "no of releases")
# artists with most releases
album_data %>% group_by(Artist = track_artist) %>%
summarise(No_of_tracks = n()) %>%
arrange(desc(No_of_tracks)) %>%
top_n(15, wt = No_of_tracks) %>%
ggplot(aes(x = Artist, y = No_of_tracks, fill = No_of_tracks)) +
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "blue2", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+labs(height=10, width=5)+
coord_flip() + labs(title = "artists with the most releases", x = "artists", y = "no of releases")
# artists with most releases
album_data %>% group_by(Artist = track_artist) %>%
summarise(No_of_tracks = n()) %>%
arrange(desc(No_of_tracks)) %>%
top_n(15, wt = No_of_tracks) %>%
ggplot(aes(x = Artist, y = No_of_tracks, fill = No_of_tracks)) +
geom_bar(position = "dodge", stat="identity")+
scale_fill_gradient(low = "blue2", high = "springgreen3")+
theme_light()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+labs(height=10, width=5)+
coord_flip() + labs(title = "artists with the most releases", x = "artists", y = "no of releases")
install.packages("StatsBombR")
devtools::install_github("statsbomb/SDMTools")
library(StatsBombR)
devtools::install_github("statsbomb/StatsBombR")
library(devtools)
devtools::install_github("statsbomb/StatsBombR")
library(StatsBombR)
install_git("ggsoccer")
install.packages("ggsoccer")
library(ggsoccer)
comp <- FreeCompetitions()
Comp %>%
filter(competition_id==14 & season_name=="2012/2013")
library(tidyverse)
Comp %>%
filter(competition_id==14 & season_name=="2012/2013")
comp
View(comp)
comp %>%
filter(competition_id==27 & season_name=="2012/2013")
premiere_league <- comp %>%
filter(competition_id==27 & season_name=="2015/2016")
comp
premier_league <- comp %>%
filter(competition_id==27 & season_name=="2015/2016")
premier_league
# Retrieve all available matches
matches <- FreeMatches(ucl_german)
# Retrieve all available matches
matches <- FreeMatches(premier_league)
# Retrieve all available matches
matches <- FreeMatches(premier_league)
# Retrieve all available matches
matchesT <- FreeMatches(premier_league)
matchesT
install.packages("jpeg")
library(jpeg)
install.packages("EBImage")
install.packages("EBImage")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EBImage")
library(EBImage)
update.packages("htmltools")
library(htmltools)
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
install.packages("htmltools")
knitr::opts_chunk$set(echo = TRUE)
# import car dataset
require(car)
head(car)
# import car dataset
require(car)
head(cars)
library(dplyr)
library(ggplot2)
# import car dataset
require(carData)
library(dplyr)
library(ggplot2)
head(carData)
# import car dataset
require(carData)
library(dplyr)
library(ggplot2)
head(cars)
dim(cars)
dim(cars)
summary(cars)
plot(cars[,"speed"],cars[,"dist"], main= "speed vs distance",
xlab="speed", ylab="Distance")
# Plotting the line plot (dist vs. speed)
plot(cars$speed, cars$dist, type = "l", col = "blue", lwd = 2,
xlab = "Speed (mph)", ylab = "Stopping Distance (feet)",
main = "Stopping Distance vs. Speed")
# Add grid lines to the plot
grid()
# Add a legend to the plot
legend("topright", legend = "Stopping Distance", col = "blue", lty = 1, lwd = 2)
# Add a title to the plot
title(main = "Stopping Distance vs. Speed", col.main = "blue", font.main = 1)
# Create a relationship plot (scatter plot with regression line and marginal distributions)
relationship_plot <- ggplot(cars, aes(x = speed, y = dist)) +
geom_point(color = "blue", alpha = 0.7) +  # Scatter plot of speed vs. dist
geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add a linear regression line
labs(x = "Speed (mph)", y = "Stopping Distance (feet)",
title = "Relationship Between Speed and Stopping Distance") +  # Axis labels and title
theme_minimal() +  # Minimal theme for the plot
theme(plot.title = element_text(size = 14, face = "bold")) +  # Customize plot title
# Add marginal density plots for x (speed) and y (dist)
marginal_histograms(bins = 20, color = "gray", fill = "lightblue")
library(ggplot2)
# Create a relationship plot (scatter plot with regression line and marginal distributions)
relationship_plot <- ggplot(cars, aes(x = speed, y = dist)) +
geom_point(color = "blue", alpha = 0.7) +  # Scatter plot of speed vs. dist
geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add a linear regression line
labs(x = "Speed (mph)", y = "Stopping Distance (feet)",
title = "Relationship Between Speed and Stopping Distance") +  # Axis labels and title
theme_minimal() +  # Minimal theme for the plot
theme(plot.title = element_text(size = 14, face = "bold")) +  # Customize plot title
# Add marginal density plots for x (speed) and y (dist)
marginal_histograms(bins = 20, color = "gray", fill = "lightblue")
# Display the relationship plot
print(relationship_plot)
plot(cars[,"speed"],cars[,"dist"], main= "speed vs distance",
xlab="speed", ylab="Distance")
plot(cars[,"speed"],cars[,"dist"], main= "speed vs distance",
xlab="speed", ylab="Distance")
# see how data is skewed
ggplot(cars, aes(x=speed)) +
geom_histogram(binwidth = 5, fill="grey", color="black") +
labs(title="Histogram of Car Speeds", x="Speed (mph)", y="Frequency") +
theme_minimal()
cars_model <- lm(dist ~ speed, data = cars)
summary(cars_model)
cars_model <- lm(dist ~ speed, data = cars)
summary(cars_model)
abline(cars)
abline(cars_model)
abline(cars_model)
require(ResourceSelection)
install.packages("ResourceSelection")
require(ResourceSelection)
kdepairs(cars)
# import car dataset
require(carData)
library(dplyr)
library(ggplot2)
head(cars)
dim(cars)
require(ResourceSelection)
kdepairs(cars)
# import car dataset
require(carData)
library(dplyr)
library(ggplot2)
head(cars)
dim(cars)
require(ResourceSelection)
kdepairs(cars)
cars_model <- lm(dist ~ speed, data = cars)
summary(cars_model)
abline(cars_model, col='red')
abline(lm(speed ~ dist, data=cars))
cars_model <- lm(dist ~ speed, data = cars) + abline()
par(ask=F)
par(mfrow=c(2,2))
plot(cars_model)
hist(cars_model$residuals)
cars_model <- lm(dist ~ speed, data = cars)
summary(cars_model)
par(ask=F)
par(mfrow=c(2,2))
plot(cars_model)
hist(cars_model$residuals)
plot(fitted(cars_model, resid(cars_model)))
qqnorm(resid(cars_model))
qqline(resid(cars_model))
par(mfrow=c(2,2))
plot(cars_model)
par(ask=F)
par(mfrow=c(2,2))
plot(cars_model)
plot(fitted(cars_model, resid(cars_model)))
qqnorm(resid(cars_model))
qqline(resid(cars_model))
par(mfrow=c(2,2))
plot(cars_model)
par(ask=F)
par(mfrow=c(2,2))
plot(cars_model)
plot(fitted(cars_model, resid(cars_model)))
qqnorm(resid(cars_model))
qqline(resid(cars_model))
par(mfrow=c(2,2))
plot(cars_model)
par(ask=F)
par(mfrow=c(2,2))
plot(cars_model)
plot(fitted(cars_model, resid(cars_model)))
qqnorm(resid(cars_model))
qqline(resid(cars_model))
corr(cars)
cor(cars)
ggplot(cars, aes(x = speed, y = dist)) +
geom_point() +
geom_smooth(method = "lm", color = "red") +
labs(title = "Impact of Car Speed on Car Stopping Distance",
x = "Speed (mph)",
y = "Stopping Distance (ft)") +
theme_minimal()
# Plot model residuals on y axis, fitted values on x axis
# Add red trend curve with better choice of smoothing bandwidth
qplot(y = cars_model$residuals, x = cars_model$fitted.values,
ylab = "Residuals", xlab = "Fitted values",
main = "The Do-it-yourself Residuals vs. Fitted plot") +
stat_smooth(method = "loess", span = 0.1, colour = I("red"), se = FALSE)
# Plot model residuals on y axis, fitted values on x axis
# Add red trend curve with better choice of smoothing bandwidth
qplot(y = cars_model$residuals, x = cars_model$fitted.values,
ylab = "Residuals", xlab = "Fitted values",
main = "The Do-it-yourself Residuals vs. Fitted plot") +
stat_smooth(method = "loess", span = 0.1, colour = I("red"), se = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot)
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv')
train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
head(test)
head(train)
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv')
train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
head(test)
head(train)
dim(test) & dim(train)
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv')
train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
head(test)
head(train)
dim(test) , dim(train)
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv')
train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
head(test)
head(train)
dim(test)
dim(train)
# Check for NA and missing values
# is.na return a vector with value TT for missing values.
numberOfNA = length(which(is.na(train)==T))
if(numberOfNA > 0) {
cat('Number of missing values found: ', numberOfNA)
cat('\nRemoving missing values...')
train = train[complete.cases(train), ]
}
# Check for NA and missing values
# is.na return a vector with value TT for missing values.
numberOfNA = length(which(is.na(train)==T))
if(numberOfNA > 0) {
cat('Number of missing values found: ', numberOfNA)
cat('\nRemoving missing values...')
train = train[complete.cases(train), ]
}
corr(train$x,train$y)
# Check for NA and missing values
# is.na return a vector with value TT for missing values.
numberOfNA = length(which(is.na(train)==T))
if(numberOfNA > 0) {
cat('Number of missing values found: ', numberOfNA)
cat('\nRemoving missing values...')
train = train[complete.cases(train), ]
}
cor(train$x,train$y)
dna_lm <- lm(x,y, data = train)
dna_lm <- lm(y~., data = train)
summary(dna_lm)
require(ResourceSelection)
kdepairs(cars)
dna_lm <- lm(y~., data = train)
summary(dna_lm)
require(ResourceSelection)
kdepairs(train)
dna_lm <- lm(y~., data = train)
summary(dna_lm)
par(ask=F)
par(mfrow=c(2,2))
plot(dna_lm)
hist(dna_lm$residuals)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv') train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv') train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv') train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv'
library(ggplot2)
library(dplyr)
test <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/test.csv')
train <- read.csv('https://raw.githubusercontent.com/joewarner89/DATA-605-Computational-Mathematics/main/Assignment/week%2012/train.csv')
# Check for NA and missing values
# is.na return a vector with value TT for missing values.
numberOfNA = length(which(is.na(train)==T))
if(numberOfNA > 0) {
cat('Number of missing values found: ', numberOfNA)
cat('\nRemoving missing values...')
train = train[complete.cases(train), ]
}
cor(train$x,train$y)
require(ResourceSelection)
#summarize the data set
kdepairs(train)
#creating the model
dna_lm <- lm(y~., data = train) summary(dna_lm)
require(ResourceSelection)
#summarize the data set
kdepairs(train)
#creating the model
dna_lm <- lm(y~., data = train)
summary(dna_lm)
library(calculus)
install.packages("calculus")
library(calculus)
myf=function(x) 1/x
taylor(myf, var=c(x=1), order=6)
myf=function(x) 1/(1-x)
taylor(myf, var=c(x=1), order=6)
knitr::opts_chunk$set(echo = TRUE)
library(calculus)
myf=function(x) 1/(1-x)
taylor(myf, var=c(x=1), order=6)
myf=function(x) e^x
taylor(myf, var=c(x=1), order=6)
myf=function(x) exp(x)
taylor(myf, var=c(x=1), order=6)
myf=function(x) log1p(x)
taylor(myf, var=c(x=1), order=6)
myf=function(x) log1p(x)
taylor(myf, var=c(x=1), order=6)
myf=function(x) x^(1/2)
taylor(myf, var=c(x=1), order=6)
myf=function(x) x^(1/2)
taylor(myf, var=c(x=1), order=6)
myf=function(x) exp(x)
taylor(myf, var=c(x=0), order=6)
myf=function(x) sin(x)
taylor(myf, var=c(x=0), order=6)
knitr::opts_chunk$set(echo = TRUE)
myf=function(x) sin(x)
taylor(myf, var=c(x=0), order=6)
myf=function(x) tan(x)
taylor(myf, var=c(x=0), order=6)
knitr::opts_chunk$set(echo = TRUE)
# Loading library
library(tidyverse)
library(ggplot2)
library(DataExplorer)
library(mice)
library(kableExtra)
library(corrplot)
library(reshape)
library(reshape2)
library(caret)
library(dplyr)
library(factoextra)
library(caret)  # for data splitting and pre-processing
library(stats)
setwd("~/CUNY/DATA 621 - Data Mining/Week 4/Data")
# load data money ball
#evaluation set use for test set
money_ball_eval <- read.csv('moneyball-evaluation-data.csv')
# training  set
money_ball_train <- read.csv('moneyball-training-data.csv')
str(money_ball_train)
introduce(money_ball_train)
# Data Description
money_ball_train %>%
summary() %>%
kable() %>% kable_styling() %>%  kable_classic(full_width = F, html_font = "Cambria")
str(money_ball_train)
# Correlation Plot
cor_matrix <- cor(money_ball_train, use = 'complete.obs')
corrplot(cor_matrix, method = 'circle')
money <- money_ball_train
# Create missing data flags
# Create missing data flags
#missing_flag <- ifelse(is.na(money_ball_train$TEAM_BATTING_HBP), 1, 2)
#money_ball_train$missing_flag <- missing_flag
par(mfrow=c(3,3))
# Create distribution plot to check outliers
for (i in 1:17) {
hist(money[,i],main=names(money[i]),xlab=names(money[i]),breaks = 51)
boxplot(money[,i], main=names(money[i]), type="l",horizontal = TRUE)
plot(money[,i], money$TARGET_WINS, main = names(money[i]), xlab=names(money[i]))
abline(lm(money$TARGET_WINS ~ money[,i], data = money), col = "blue")
}
calculate_correlations_with_pvalues <- function(data, target_col) {
# Check if target_col is a character string
if (!is.character(target_col) || length(target_col) != 1) {
stop("target_col must be a single character string.")
}
# Ensure the target column exists in the data
if (!target_col %in% names(data)) {
stop("Target column not found in the dataframe.")
}
# Remove rows with missing values
data_complete <- data[complete.cases(data), ]
# Initialize a results data frame
results <- data.frame(Predictor = character(), Correlation = numeric(), PValue = numeric(), stringsAsFactors = FALSE)
# Loop through each predictor variable
for (predictor in names(data_complete)[names(data_complete) != target_col]) {
# Perform the correlation test
test_result <- cor.test(data_complete[[predictor]], data_complete[[target_col]])
# Store the rounded results to 10 decimal places
results <- rbind(results, data.frame(Predictor = predictor,
Correlation = round(test_result$estimate, 10),
PValue = round(test_result$p.value, 10)))
}
return(results)
}
# Example usage
correlation_results <- calculate_correlations_with_pvalues(money_ball_train, "TARGET_WINS")
# View the results
print(correlation_results)
#
plot_intro(money_ball_train, title = 'Missing Information on Meny Ball Dataset',
ggtheme = theme_minimal())
# Plot missing volume in Column
plot_missing(money_ball_train,title = 'Information about Missing Value in money ball dataset',ggtheme = theme_minimal())
setwd("~/CUNY/DATA 621 - Data Mining/Week5")
